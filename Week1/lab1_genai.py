# -*- coding: utf-8 -*-
"""lab1_GenAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tLWEsSgNKtrvXrr6I_1uQj8h5VRDELi1
"""

import torch
from diffusers import StableDiffusionPipeline
import os
import matplotlib.pyplot as plt


model_id = "runwayml/stable-diffusion-v1-5"

print("Loading the model... this may take a minute.")
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)

# Move the model to GPU for faster generation
pipe = pipe.to("cuda")
print("Model loaded successfully!")


prompts = [
    "A futuristic city with flying cars and neon lights, cyberpunk style",
    "A cute astronaut cat exploring Mars, high detail, 4k",
    "A serene lake surrounded by snowy mountains at sunset",
    "A robot painting a canvas in an art studio, oil painting style",
    "A medieval castle floating on a cloud, fantasy art"
]


output_folder = "synthetic_dataset"
os.makedirs(output_folder, exist_ok=True)

generated_images = []

print(f"\nStarting generation of {len(prompts)} images...")

for i, prompt in enumerate(prompts):
    print(f"Generating sample {i+1}: {prompt}")

    # Generate the image
    # We use a distinct seed for reproducibility (optional but good practice)
    generator = torch.Generator("cuda").manual_seed(1024 + i)
    image = pipe(prompt, generator=generator).images[0]

    # Save generated output in the folder
    file_path = f"{output_folder}/generated_sample_{i+1}.png"
    image.save(file_path)

    # Store in list for display
    generated_images.append((prompt, image))

print(f"\nAll images have been saved to the '{output_folder}' directory.")

# ==========================================
# 4. DISPLAY SAMPLE OUTPUTS
# ==========================================
# Display the generated samples as required
plt.figure(figsize=(20, 5))

for i, (prompt, img) in enumerate(generated_images):
    plt.subplot(1, 5, i+1)
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Sample {i+1}")

plt.show()

# Print the text mapping
for i, prompt in enumerate(prompts):
    print(f"Sample {i+1}: {prompt}")